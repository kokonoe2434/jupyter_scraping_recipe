{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "\u001b[K     |████████████████████████████████| 904 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from selenium) (1.25.10)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.1-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.1\n",
      "Collecting chromedriver-binary\n",
      "  Downloading chromedriver-binary-88.0.4324.27.1.tar.gz (4.3 kB)\n",
      "Building wheels for collected packages: chromedriver-binary\n",
      "  Building wheel for chromedriver-binary (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chromedriver-binary: filename=chromedriver_binary-88.0.4324.27.1-py3-none-any.whl size=5703387 sha256=cecead8eb90e305b40115f508b10362e4a1780ec77043189e5e8e06046765c5d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/9b/18/ff/2ea0afc8af8c30addd71d6738029b54ed059531819185a2238\n",
      "Successfully built chromedriver-binary\n",
      "Installing collected packages: chromedriver-binary\n",
      "Successfully installed chromedriver-binary-88.0.4324.27.1\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Downloading pytz-2020.5-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.19.4 pandas-1.2.0 pytz-2020.5\n",
      "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.7/site-packages (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install chromedriver-binary\n",
    "!pip install pandas\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lyric/ja00010744/\n",
      "/lyric/jb10707155/\n",
      "/lyric/yi15051933/\n",
      "/lyric/ja00011136/\n",
      "/lyric/ja00010591/\n",
      "/lyric/ay17032211/\n",
      "/lyric/yi15051923/\n",
      "/lyric/ay17032203/\n",
      "/lyric/ay17032208/\n",
      "/lyric/ay17032209/\n",
      "/lyric/ay17032201/\n",
      "/lyric/ay17032204/\n",
      "/lyric/ay17032206/\n",
      "/lyric/ay17032207/\n",
      "/lyric/ay17032212/\n",
      "/lyric/ay17032202/\n",
      "/lyric/ay17032205/\n",
      "/lyric/ay17032210/\n",
      "/lyric/ay17032213/\n",
      "/lyric/yi15051924/\n",
      "/lyric/yi15051926/\n",
      "/lyric/uz19062604/\n",
      "/lyric/sa17060713/\n",
      "/lyric/yi15051901/\n",
      "/lyric/yi15051902/\n",
      "/lyric/jb51009246/\n",
      "/lyric/yi15051920/\n",
      "/lyric/yi15051925/\n",
      "/lyric/yi15051929/\n",
      "/lyric/yi15051931/\n",
      "/lyric/yi15051937/\n",
      "/lyric/yi15051951/\n",
      "/lyric/ja00010573/\n",
      "/lyric/yi15051904/\n",
      "/lyric/ya17070503/\n",
      "/lyric/jb20806189/\n",
      "/lyric/jb51009245/\n",
      "/lyric/yi15051910/\n",
      "/lyric/yi15051913/\n",
      "/lyric/yi15051917/\n",
      "/lyric/yi15051918/\n",
      "/lyric/yi15051919/\n",
      "/lyric/yi15051927/\n",
      "/lyric/yi15051932/\n",
      "/lyric/ja00011582/\n",
      "/lyric/yi15051936/\n",
      "/lyric/yi15051938/\n",
      "/lyric/yi15051948/\n",
      "/lyric/yi15051949/\n",
      "/lyric/yi15051952/\n",
      "/lyric/yi15051957/\n",
      "/lyric/yi15051959/\n",
      "/lyric/ya17070504/\n",
      "/lyric/jb51003165/\n",
      "/lyric/jb51003166/\n",
      "/lyric/jb20806188/\n",
      "/lyric/jb51009241/\n",
      "/lyric/jb51009244/\n",
      "/lyric/jb10702116/\n",
      "/lyric/yi15051905/\n",
      "/lyric/yi15051911/\n",
      "/lyric/yi15051912/\n",
      "/lyric/yi15051914/\n",
      "/lyric/yi15051921/\n",
      "/lyric/yi15051928/\n",
      "/lyric/yi15051930/\n",
      "/lyric/yi15051934/\n",
      "/lyric/yi15051941/\n",
      "/lyric/yi15051944/\n",
      "/lyric/yi15051945/\n",
      "/lyric/yi15051950/\n",
      "/lyric/yi15051953/\n",
      "/lyric/yi15051955/\n",
      "/lyric/yi15051961/\n",
      "/lyric/ya17070505/\n",
      "/lyric/ya17070506/\n",
      "/lyric/jb51003160/\n",
      "/lyric/jb51003161/\n",
      "/lyric/jb51003162/\n",
      "/lyric/jb51003163/\n",
      "/lyric/jb51003164/\n",
      "/lyric/jb51003167/\n",
      "/lyric/jb71001197/\n",
      "/lyric/jb70912059/\n",
      "/lyric/jb70909170/\n",
      "/lyric/jb70909171/\n",
      "/lyric/jb70909172/\n",
      "/lyric/jb20806190/\n",
      "/lyric/jb20806191/\n",
      "/lyric/jb20806192/\n",
      "/lyric/jb20806193/\n",
      "/lyric/jb20806194/\n",
      "/lyric/jb10708194/\n",
      "/lyric/jb51009242/\n",
      "/lyric/jb51009243/\n",
      "/lyric/jb51009247/\n",
      "/lyric/jb51009248/\n",
      "/lyric/jb51009249/\n",
      "/lyric/jb10702115/\n",
      "/lyric/jb10611022/\n",
      "/lyric/jb10611023/\n",
      "/lyric/yi15051903/\n",
      "/lyric/yi15051906/\n",
      "/lyric/yi15051907/\n",
      "/lyric/yi15051908/\n",
      "/lyric/yi15051909/\n",
      "/lyric/yi15051915/\n",
      "/lyric/yi15051916/\n",
      "/lyric/ja00012007/\n",
      "/lyric/yi15051922/\n",
      "/lyric/yi15051935/\n",
      "/lyric/ja00011363/\n",
      "/lyric/yi15051939/\n",
      "/lyric/yi15051940/\n",
      "/lyric/ja00010258/\n",
      "/lyric/yi15051942/\n",
      "/lyric/yi15051943/\n",
      "/lyric/yi15051946/\n",
      "/lyric/yi15051947/\n",
      "/lyric/yi15051954/\n",
      "/lyric/yi15051956/\n",
      "/lyric/yi15051958/\n",
      "/lyric/yi15051960/\n",
      "終了\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import time\n",
    "start = time.time()\n",
    "url_base_artist = 'https://utaten.com/artist/lyric/'\n",
    "url_base_lyric = 'https://utaten.com'\n",
    "url_lyrics = []\n",
    "for idx_artist in range(1, 2):\n",
    "    if idx_artist % 1000 == 0:\n",
    "        print(idx)\n",
    "    url_str = url_base_artist + str(idx_artist)\n",
    "    r = requests.get(url_str)\n",
    "    if r.url == url_str:\n",
    "        data = BeautifulSoup(r.text, 'html.parser')\n",
    "        elm_bread_last = data.find('li', class_='pager__item pager__item--last')\n",
    "        for child in elm_bread_last.children:\n",
    "            if child.name == 'a':\n",
    "                page_str = child['href']\n",
    "                page_last = int(page_str[-1:]) + 1\n",
    "                for idx_bread in range(1, page_last):\n",
    "                    url_str = url_base_artist + str(idx_artist) + '?page=' + str(idx_bread)\n",
    "                    r = requests.get(url_str)\n",
    "                    data = BeautifulSoup(r.text, 'html.parser')\n",
    "                    elm_lyrics_url = data.find_all('p', class_='searchResult__title')\n",
    "                    for elm_p in elm_lyrics_url:\n",
    "                        for child in elm_p.children:\n",
    "                            if child.name == 'a':\n",
    "                                print(child['href'])\n",
    "                                url_lyrics.append(child['href'])\n",
    "        for lyric_url in url_lyrics:\n",
    "            lyric_url = url_base_lyric + lyric_url\n",
    "            r = requests.get(lyric_url)\n",
    "            data = BeautifulSoup(r.text, 'html.parser')\n",
    "            elem = data.find('div', class_='romaji')\n",
    "            kashi_list_huri = []\n",
    "            kashi_list_kaki = []\n",
    "            for e in elem.children:\n",
    "                if e.name == 'br':\n",
    "                    kashi_list_huri.append('\\n')\n",
    "                    kashi_list_kaki.append('\\n')\n",
    "                elif type(e) is NavigableString:\n",
    "                    pass\n",
    "                else:\n",
    "                    elm_kashi_huri = e.find(\"span\", class_=\"rt\")\n",
    "                    elm_kashi_kaki = e.find(\"span\", class_=\"rb\")\n",
    "                    kashi_list_huri.append(elm_kashi_huri.text)\n",
    "                    kashi_list_kaki.append(elm_kashi_kaki.text)\n",
    "            kashi_list = zip(kashi_list_huri, kashi_list_kaki)\n",
    "            count_start = 0\n",
    "            count_end = 0\n",
    "            print_huri = ''\n",
    "            print_kaki = ''\n",
    "            elem_bread = data.find_all('span', itemprop='name')\n",
    "            print(elem_bread[1].text + '***********' + elem_bread[2].text.replace('歌詞', ''))\n",
    "            for huri in kashi_list_huri:\n",
    "                if huri == '\\n':\n",
    "                    for idx in range(count_start, count_end):\n",
    "                        print_kaki += kashi_list_kaki[idx]\n",
    "                    print(print_huri + '\\t' + print_kaki)\n",
    "                    print_huri = ''\n",
    "                    print_kaki = ''\n",
    "                    count_start = count_end + 1\n",
    "                    count_end += 1\n",
    "                else:\n",
    "                    print_huri += huri\n",
    "                    count_end += 1\n",
    "\"\"\"\n",
    "    for idx in range(19073145, 19073147):\n",
    "        url_str = url_base\n",
    "        url_str = 'https://utaten.com/lyric/' + url_str + str(idx) + '/'\n",
    "        r = requests.get(url_str) \n",
    "        print( r.url + '   -------->   ' + url_str)\n",
    "        if r.url == url_str:\n",
    "            data = BeautifulSoup(r.text, 'html.parser')\n",
    "            elem = data.find('div', class_='romaji')\n",
    "            kashi_list_huri = []\n",
    "            kashi_list_kaki = []\n",
    "            for e in elem.children:\n",
    "                if e.name == 'br':\n",
    "                    kashi_list_huri.append('\\n')\n",
    "                    kashi_list_kaki.append('\\n')\n",
    "                elif type(e) is NavigableString:\n",
    "                    pass\n",
    "                else:\n",
    "                    elm_kashi_huri = e.find(\"span\", class_=\"rt\")\n",
    "                    elm_kashi_kaki = e.find(\"span\", class_=\"rb\")\n",
    "                    kashi_list_huri.append(elm_kashi_huri.text)\n",
    "                    kashi_list_kaki.append(elm_kashi_kaki.text)\n",
    "            kashi_list = zip(kashi_list_huri, kashi_list_kaki)\n",
    "            count_start = 0\n",
    "            count_end = 0\n",
    "            print_huri = ''\n",
    "            print_kaki = ''\n",
    "            elem_bread = data.find_all('span', itemprop='name')\n",
    "            print(elem_bread[1].text + '***********' + elem_bread[2].text.replace('歌詞', ''))\n",
    "            for huri in kashi_list_huri:\n",
    "                if huri == '\\n':\n",
    "                    for idx in range(count_start, count_end):\n",
    "                        print_kaki += kashi_list_kaki[idx]\n",
    "                    print(print_huri + '\\t' + print_kaki)\n",
    "                    print_huri = ''\n",
    "                    print_kaki = ''\n",
    "                    count_start = count_end + 1\n",
    "                    count_end += 1\n",
    "                else:\n",
    "                    print_huri += huri\n",
    "                    count_end += 1\n",
    "\"\"\"\n",
    "print('終了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
